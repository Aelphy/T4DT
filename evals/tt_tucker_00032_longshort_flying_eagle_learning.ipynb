{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b1a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tntorch as tn\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c374c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_tucker = torch.load('../logs/tt_tucker_r80_00032_longshort_flying_eagle.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31552a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 1.0077e+05,  2.9927e+00, -1.2513e+00,  ..., -1.3361e-17,\n",
       "           -8.2831e-18, -5.4773e-18],\n",
       "          [-4.8448e-01,  1.6362e+04,  1.1623e+02,  ...,  1.8787e-16,\n",
       "            2.2989e-16,  1.8329e-16],\n",
       "          [-1.6768e-01,  9.4330e+01, -1.3278e+04,  ..., -6.2502e-16,\n",
       "            3.4494e-16, -4.1234e-17],\n",
       "          ...,\n",
       "          [-1.4211e-13,  1.5846e-12,  1.4467e-13,  ..., -5.8764e-11,\n",
       "           -5.5224e-11,  1.1366e-10],\n",
       "          [ 1.7053e-13, -5.1936e-13, -1.2076e-13,  ...,  8.5128e-11,\n",
       "           -3.8273e-10,  1.2300e-11],\n",
       "          [-1.8190e-12, -8.5639e-13, -9.3122e-13,  ..., -3.2350e-10,\n",
       "           -4.5473e-10,  5.7045e-11]]], dtype=torch.float64, requires_grad=True),\n",
       " tensor([[[-9.9237e-01, -4.6216e-04,  2.4600e-04,  ...,  6.6905e-22,\n",
       "            3.1459e-22, -5.4155e-24],\n",
       "          [ 9.5309e-04, -4.7110e-02,  8.3792e-02,  ..., -1.8391e-21,\n",
       "           -8.7373e-22,  1.9853e-22],\n",
       "          [-7.0584e-03,  2.0689e-02,  2.1442e-03,  ..., -1.8263e-21,\n",
       "           -5.2517e-22, -1.2928e-21],\n",
       "          ...,\n",
       "          [ 3.1079e-08, -3.9314e-08,  1.9292e-09,  ...,  6.5207e-17,\n",
       "           -2.4483e-17,  5.0996e-18],\n",
       "          [ 1.4561e-09, -2.6102e-09,  2.0275e-08,  ...,  8.7717e-19,\n",
       "           -2.5403e-18, -6.0508e-18],\n",
       "          [ 2.1362e-08, -2.1719e-08, -3.3428e-08,  ...,  6.8654e-17,\n",
       "           -1.2168e-17,  1.7106e-17]],\n",
       " \n",
       "         [[-7.4729e-03, -8.8672e-01, -1.6171e-01,  ...,  9.3909e-22,\n",
       "           -2.2093e-21, -7.0155e-23],\n",
       "          [-3.6204e-03, -8.5553e-02, -1.6041e-01,  ..., -1.3920e-21,\n",
       "            1.4598e-20,  7.6213e-22],\n",
       "          [ 5.1694e-02,  5.2594e-02,  8.5913e-03,  ..., -1.3054e-20,\n",
       "           -1.4651e-21, -5.8864e-21],\n",
       "          ...,\n",
       "          [-5.8159e-07, -1.0018e-06, -1.0272e-07,  ..., -2.0791e-17,\n",
       "            4.4262e-16, -1.2125e-16],\n",
       "          [-8.6062e-08, -5.2549e-08,  7.3704e-08,  ...,  2.1497e-17,\n",
       "           -8.7019e-18, -8.2237e-17],\n",
       "          [-2.3770e-07, -6.7045e-07, -1.3771e-07,  ..., -1.2899e-16,\n",
       "            4.7555e-16,  1.4267e-16]],\n",
       " \n",
       "         [[-2.2128e-03,  4.4376e-02, -2.9045e-01,  ..., -8.2662e-22,\n",
       "           -2.7508e-21,  2.5186e-21],\n",
       "          [ 9.2772e-02, -5.9279e-02, -3.0331e-03,  ...,  1.3153e-21,\n",
       "            1.0132e-20, -1.0475e-20],\n",
       "          [ 5.9659e-02, -5.4571e-02,  1.9400e-01,  ...,  8.8017e-21,\n",
       "            1.3139e-20,  4.7580e-21],\n",
       "          ...,\n",
       "          [ 2.2129e-06,  3.9738e-07,  2.6360e-07,  ..., -1.2129e-16,\n",
       "           -6.0384e-16,  1.1723e-16],\n",
       "          [ 2.2878e-07, -1.5153e-07,  2.9043e-08,  ..., -3.3132e-17,\n",
       "           -1.1477e-16,  5.3281e-17],\n",
       "          [ 1.0736e-06,  7.5743e-07,  2.1241e-07,  ..., -1.8536e-17,\n",
       "           -2.6233e-16, -1.0565e-17]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 2.3605e-04,  1.5282e-03,  3.7288e-05,  ...,  6.3377e-08,\n",
       "           -2.8485e-08,  2.9610e-08],\n",
       "          [-2.2823e-03, -3.2243e-03, -2.9098e-03,  ...,  6.9314e-08,\n",
       "            2.9000e-08,  5.0069e-10],\n",
       "          [-2.6576e-03, -3.6422e-03,  7.4907e-04,  ...,  3.6413e-08,\n",
       "           -6.6390e-08,  3.0703e-08],\n",
       "          ...,\n",
       "          [-2.0223e-05,  6.7968e-05, -1.2670e-05,  ...,  2.8104e-10,\n",
       "           -2.4726e-10, -4.4987e-10],\n",
       "          [ 9.1543e-06,  4.1686e-05,  1.4405e-06,  ...,  8.5160e-11,\n",
       "            1.7771e-11, -7.9987e-11],\n",
       "          [-6.1798e-05, -7.8904e-05, -2.3745e-05,  ...,  9.9131e-11,\n",
       "           -3.5451e-10, -5.6111e-12]],\n",
       " \n",
       "         [[ 5.0172e-05, -8.0131e-05,  1.8234e-03,  ...,  6.4557e-09,\n",
       "            3.1764e-08,  1.3794e-08],\n",
       "          [ 3.2878e-03, -2.4632e-03,  6.7854e-04,  ..., -1.1197e-09,\n",
       "            3.5400e-08,  9.4053e-09],\n",
       "          [ 1.7549e-04, -1.7248e-03,  7.1479e-04,  ..., -1.3853e-08,\n",
       "           -1.0697e-07,  1.8310e-07],\n",
       "          ...,\n",
       "          [ 2.6099e-05,  1.6861e-04,  7.7973e-06,  ...,  5.9495e-10,\n",
       "            2.7132e-10, -7.7963e-10],\n",
       "          [-2.5745e-05,  3.7842e-05, -1.7320e-05,  ...,  6.3184e-11,\n",
       "            2.0792e-11, -1.3540e-10],\n",
       "          [ 6.7884e-05,  4.7599e-05,  3.8214e-05,  ...,  4.8020e-10,\n",
       "            4.0606e-11, -3.1601e-11]],\n",
       " \n",
       "         [[ 3.1620e-04, -8.4461e-04, -2.6696e-03,  ...,  1.2622e-07,\n",
       "            1.4500e-08, -1.7651e-07],\n",
       "          [ 4.6332e-03, -1.0425e-03,  3.2533e-03,  ...,  3.2549e-08,\n",
       "            1.5205e-08, -1.1025e-07],\n",
       "          [ 6.1349e-03,  5.1198e-03,  2.0638e-03,  ...,  5.0483e-08,\n",
       "           -8.5998e-08, -7.4580e-09],\n",
       "          ...,\n",
       "          [ 2.7022e-05,  5.6914e-05,  1.1498e-05,  ..., -1.3321e-10,\n",
       "           -1.1934e-10,  4.3710e-10],\n",
       "          [-5.1697e-06,  5.9467e-05, -5.2994e-06,  ..., -3.6061e-11,\n",
       "           -1.7669e-10,  1.5598e-10],\n",
       "          [ 1.2213e-05, -9.0084e-05,  1.3046e-05,  ..., -1.3996e-10,\n",
       "            5.4002e-10, -2.4713e-10]]], dtype=torch.float64, requires_grad=True),\n",
       " tensor([[[-9.9816e-01, -1.1363e-03, -4.3602e-04,  ...,  3.3308e-06,\n",
       "           -1.8355e-06,  5.0424e-07],\n",
       "          [-3.0952e-03, -6.3321e-03, -3.4811e-02,  ..., -4.7625e-06,\n",
       "           -1.0257e-05, -3.6936e-06],\n",
       "          [-3.1376e-03, -1.0413e-03, -8.0929e-03,  ...,  8.4947e-06,\n",
       "            1.8065e-05,  2.0737e-05],\n",
       "          ...,\n",
       "          [ 1.3818e-08,  2.9954e-08,  2.5832e-07,  ...,  7.4396e-09,\n",
       "           -1.3273e-08, -1.3753e-08],\n",
       "          [ 1.1660e-08, -6.5032e-09, -2.1676e-07,  ..., -1.4182e-08,\n",
       "            2.2828e-08, -2.7255e-10],\n",
       "          [ 1.6535e-09, -6.0729e-08, -2.0263e-07,  ...,  1.8139e-08,\n",
       "           -2.9658e-08, -2.7674e-08]],\n",
       " \n",
       "         [[ 2.6118e-03, -1.5557e-01, -8.4950e-02,  ..., -3.4960e-05,\n",
       "            1.9150e-04, -5.7826e-05],\n",
       "          [-9.2718e-01,  7.0319e-02,  5.4245e-03,  ..., -1.3354e-04,\n",
       "            1.5904e-04, -1.1374e-05],\n",
       "          [-2.4256e-01, -4.0574e-02, -2.5128e-02,  ...,  8.2819e-05,\n",
       "            2.1769e-04, -1.6283e-05],\n",
       "          ...,\n",
       "          [-8.3228e-08, -3.6862e-07, -9.0714e-08,  ..., -6.9954e-08,\n",
       "            9.4412e-08,  9.6431e-08],\n",
       "          [ 3.2438e-07,  1.4427e-07, -3.7638e-07,  ...,  1.9391e-07,\n",
       "            6.9019e-08,  3.8096e-08],\n",
       "          [ 4.8529e-07,  2.3887e-07,  1.0376e-06,  ..., -5.8228e-08,\n",
       "           -6.0234e-09,  1.3119e-07]],\n",
       " \n",
       "         [[ 7.1161e-03,  6.2018e-01, -5.1191e-01,  ..., -3.0457e-05,\n",
       "           -8.5648e-05, -6.7514e-05],\n",
       "          [-7.9909e-02, -3.4436e-01, -6.8600e-02,  ...,  1.0031e-04,\n",
       "           -2.8554e-04,  1.8264e-04],\n",
       "          [-1.5970e-01,  7.7333e-02,  3.0725e-01,  ..., -1.9193e-04,\n",
       "           -2.7613e-04,  8.4791e-05],\n",
       "          ...,\n",
       "          [ 8.6470e-07,  2.1101e-07, -2.3742e-06,  ...,  3.5865e-07,\n",
       "           -5.4576e-07, -1.2659e-07],\n",
       "          [-1.7908e-07,  4.2080e-07, -2.9522e-07,  ..., -7.3677e-08,\n",
       "            2.3114e-07,  8.9839e-08],\n",
       "          [-6.4165e-07,  6.2044e-07,  4.7710e-07,  ...,  1.2551e-07,\n",
       "           -4.9152e-07, -1.9444e-07]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[-5.8416e-09, -8.8987e-09, -2.8971e-09,  ..., -4.9946e-09,\n",
       "           -8.0138e-09, -8.6273e-09],\n",
       "          [-6.4813e-08, -8.6131e-08, -1.9123e-08,  ..., -1.2277e-08,\n",
       "            2.4088e-08,  1.4388e-08],\n",
       "          [-8.1194e-10,  7.2174e-09,  7.8906e-09,  ..., -5.6768e-09,\n",
       "            1.4712e-08, -2.5656e-08],\n",
       "          ...,\n",
       "          [-2.2631e-02, -1.6123e-02, -1.0718e-02,  ..., -3.3528e-04,\n",
       "            3.3220e-04,  1.2474e-03],\n",
       "          [ 7.9709e-03,  6.0977e-03, -4.5220e-04,  ...,  9.2712e-05,\n",
       "           -1.8695e-04, -6.5000e-04],\n",
       "          [ 2.7407e-04, -1.1997e-03,  3.2829e-03,  ...,  3.9598e-04,\n",
       "            3.5726e-04, -3.6931e-04]],\n",
       " \n",
       "         [[ 9.9394e-09,  6.5288e-09, -3.3490e-09,  ..., -2.0488e-09,\n",
       "            1.5027e-09, -1.4815e-10],\n",
       "          [ 8.4547e-08,  6.3209e-08, -7.6373e-08,  ..., -2.8347e-08,\n",
       "            2.6440e-09,  4.7703e-11],\n",
       "          [-3.5888e-08, -4.5518e-08, -9.1528e-08,  ...,  9.6209e-09,\n",
       "           -4.5965e-08,  1.3426e-08],\n",
       "          ...,\n",
       "          [ 1.8485e-02,  1.5254e-02,  3.7445e-03,  ..., -6.5685e-04,\n",
       "            8.2015e-05, -1.3079e-03],\n",
       "          [-7.1263e-03, -6.0072e-03,  2.2389e-03,  ...,  3.6520e-04,\n",
       "           -1.6929e-04,  6.8208e-04],\n",
       "          [ 2.2308e-03,  6.4650e-04, -4.3190e-03,  ..., -3.9360e-04,\n",
       "            2.4416e-04,  5.4929e-04]],\n",
       " \n",
       "         [[ 3.6620e-09,  9.9093e-09, -5.5896e-10,  ..., -3.1910e-08,\n",
       "            1.3020e-08,  1.3340e-08],\n",
       "          [ 3.1888e-08,  1.4304e-08, -1.7288e-08,  ...,  2.3000e-08,\n",
       "           -7.0016e-09,  3.6917e-08],\n",
       "          [-7.0750e-08, -1.7476e-07,  1.2351e-08,  ...,  4.9277e-09,\n",
       "            2.7349e-08,  3.4443e-08],\n",
       "          ...,\n",
       "          [ 9.4614e-03,  3.4385e-02,  3.6974e-03,  ...,  1.5074e-03,\n",
       "           -6.7433e-04,  4.5359e-05],\n",
       "          [ 6.4425e-04, -5.7231e-03, -7.7404e-03,  ..., -5.4078e-04,\n",
       "            1.7244e-05, -7.7272e-04],\n",
       "          [ 1.0506e-04, -1.9226e-03,  4.6086e-03,  ...,  4.3884e-04,\n",
       "           -3.9162e-04, -1.5091e-04]]], dtype=torch.float64, requires_grad=True),\n",
       " tensor([[[-1.0000e+00],\n",
       "          [ 4.5633e-05],\n",
       "          [ 1.2382e-04],\n",
       "          ...,\n",
       "          [-1.8633e-09],\n",
       "          [-8.4014e-10],\n",
       "          [ 2.3196e-09]],\n",
       " \n",
       "         [[ 5.6108e-05],\n",
       "          [-6.9642e-01],\n",
       "          [ 7.1675e-01],\n",
       "          ...,\n",
       "          [ 7.3460e-08],\n",
       "          [ 3.3108e-08],\n",
       "          [-9.1353e-08]],\n",
       " \n",
       "         [[-1.1802e-04],\n",
       "          [-7.1659e-01],\n",
       "          [-6.9670e-01],\n",
       "          ...,\n",
       "          [-1.0496e-07],\n",
       "          [-4.7365e-08],\n",
       "          [ 1.3055e-07]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[ 6.1097e-09],\n",
       "          [ 8.6344e-08],\n",
       "          [ 4.3756e-07],\n",
       "          ...,\n",
       "          [-1.0587e-02],\n",
       "          [-2.3206e-01],\n",
       "          [ 5.1856e-01]],\n",
       " \n",
       "         [[ 5.9294e-09],\n",
       "          [ 8.3805e-08],\n",
       "          [ 4.2464e-07],\n",
       "          ...,\n",
       "          [ 2.1159e-01],\n",
       "          [-3.3321e-01],\n",
       "          [ 5.2593e-01]],\n",
       " \n",
       "         [[ 5.6212e-09],\n",
       "          [ 7.9433e-08],\n",
       "          [ 4.0268e-07],\n",
       "          ...,\n",
       "          [-5.7015e-02],\n",
       "          [ 4.9806e-02],\n",
       "          [-2.0524e-01]]], dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[core.requires_grad_() for core in tt_tucker.cores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1dc25ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-0.0648,  0.0727,  0.0537,  ..., -0.0223,  0.0227, -0.0142],\n",
       "         [-0.0646,  0.0722,  0.0538,  ..., -0.0119,  0.0115, -0.0095],\n",
       "         [-0.0644,  0.0716,  0.0538,  ..., -0.0034,  0.0027, -0.0047],\n",
       "         ...,\n",
       "         [-0.0620,  0.0587, -0.0665,  ..., -0.0074,  0.0161,  0.0196],\n",
       "         [-0.0622,  0.0592, -0.0665,  ..., -0.0277,  0.0597,  0.0756],\n",
       "         [-0.0624,  0.0598, -0.0665,  ..., -0.0526,  0.1129,  0.1443]],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " tensor([[-4.6175e-02, -1.1925e-02, -5.3339e-02,  ...,  2.4035e-02,\n",
       "           5.8439e-04,  1.8512e-02],\n",
       "         [-4.6147e-02, -1.2013e-02, -5.3264e-02,  ...,  7.8441e-03,\n",
       "           3.1346e-04,  5.4582e-03],\n",
       "         [-4.6121e-02, -1.2098e-02, -5.3196e-02,  ..., -4.2695e-03,\n",
       "           7.8225e-05, -4.0708e-03],\n",
       "         ...,\n",
       "         [-5.3248e-02,  7.9884e-02, -3.6859e-02,  ..., -2.2047e-03,\n",
       "          -1.5415e-04, -1.7569e-03],\n",
       "         [-5.3377e-02,  7.9950e-02, -3.7480e-02,  ..., -1.5115e-02,\n",
       "          -1.3322e-03, -9.3932e-03],\n",
       "         [-5.3507e-02,  8.0013e-02, -3.8099e-02,  ..., -3.1333e-02,\n",
       "          -2.8151e-03, -1.8892e-02]], dtype=torch.float64, requires_grad=True),\n",
       " tensor([[-0.0612, -0.0172, -0.0888,  ..., -0.0203,  0.0823,  0.1545],\n",
       "         [-0.0610, -0.0167, -0.0885,  ..., -0.0157,  0.0430,  0.0786],\n",
       "         [-0.0608, -0.0163, -0.0882,  ..., -0.0103,  0.0109,  0.0167],\n",
       "         ...,\n",
       "         [-0.0704, -0.0750,  0.0129,  ...,  0.0070, -0.0024, -0.0046],\n",
       "         [-0.0706, -0.0754,  0.0126,  ...,  0.0991,  0.0038, -0.0120],\n",
       "         [-0.0708, -0.0758,  0.0123,  ...,  0.2185,  0.0127, -0.0205]],\n",
       "        dtype=torch.float64, requires_grad=True),\n",
       " tensor([[-0.0614, -0.0157, -0.0461,  ..., -0.1061,  0.0196, -0.0181],\n",
       "         [-0.0614, -0.0153, -0.0468,  ..., -0.0429, -0.0002,  0.0008],\n",
       "         [-0.0615, -0.0152, -0.0468,  ..., -0.0023, -0.0016,  0.0100],\n",
       "         ...,\n",
       "         [-0.0615, -0.0123, -0.0460,  ...,  0.0414,  0.0228, -0.0447],\n",
       "         [-0.0615, -0.0125, -0.0456,  ...,  0.0364,  0.0268, -0.0545],\n",
       "         [-0.0615, -0.0122, -0.0458,  ...,  0.0351, -0.0023, -0.0620]],\n",
       "        dtype=torch.float64, requires_grad=True)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[U.requires_grad_() for U in tt_tucker.Us]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d38f4899",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_TSDF = -0.05\n",
    "MAX_TSDF = 0.05\n",
    "NUM_EPOCHS = 100\n",
    "NUM_SAMPLES = 100000\n",
    "RES = 512\n",
    "\n",
    "optimizer = torch.optim.SGD(tt_tucker.Us + tt_tucker.cores, lr=1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a252cd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_sdf = torch.load(\n",
    "    '/scratch2/data/cape_release/meshes/00032/longshort_flying_eagle/posed/sdf_watertight_longshort_flying_eagle.000001.pt')['sdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "151edc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7846e-05, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reconstruction = tt_tucker[..., 0].torch()\n",
    "loss = torch.sqrt((reconstruction.clamp_max(MAX_TSDF).clamp_min(MIN_TSDF) -\n",
    "        gt_sdf.clamp_max(MAX_TSDF).clamp_min(MIN_TSDF))**2).mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99d9c36",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 3.906509957385132e-05\n",
      "Epoch: 1, loss: 3.646261384705368e-05\n",
      "Epoch: 2, loss: 3.8270028470228594e-05\n",
      "Epoch: 3, loss: 3.856698151915819e-05\n",
      "Epoch: 4, loss: 3.791544967697622e-05\n",
      "Epoch: 5, loss: 3.763288165714733e-05\n",
      "Epoch: 6, loss: 3.799892000675463e-05\n",
      "Epoch: 7, loss: 3.787194595731976e-05\n",
      "Epoch: 8, loss: 3.807628089589584e-05\n",
      "Epoch: 9, loss: 3.679512747785073e-05\n",
      "Epoch: 10, loss: 3.7406843195869396e-05\n",
      "Epoch: 11, loss: 3.886416371459205e-05\n",
      "Epoch: 12, loss: 3.789518809199137e-05\n",
      "Epoch: 13, loss: 3.864938457670692e-05\n",
      "Epoch: 14, loss: 3.844092546129123e-05\n",
      "Epoch: 15, loss: 3.773827505114413e-05\n",
      "Epoch: 16, loss: 3.7813343573530986e-05\n",
      "Epoch: 17, loss: 3.706643184538261e-05\n",
      "Epoch: 18, loss: 3.7599995814190985e-05\n",
      "Epoch: 19, loss: 3.8473274093241365e-05\n",
      "Epoch: 20, loss: 3.697890643322235e-05\n",
      "Epoch: 21, loss: 3.773860507369062e-05\n",
      "Epoch: 22, loss: 3.806127520682001e-05\n",
      "Epoch: 23, loss: 3.877859385704054e-05\n",
      "Epoch: 24, loss: 3.762941612304047e-05\n",
      "Epoch: 25, loss: 4.009434818902475e-05\n",
      "Epoch: 26, loss: 4.0694548343858716e-05\n",
      "Epoch: 27, loss: 3.690531018433688e-05\n",
      "Epoch: 28, loss: 3.74041965657669e-05\n",
      "Epoch: 29, loss: 3.832007193358283e-05\n",
      "Epoch: 30, loss: 3.685902395224469e-05\n",
      "Epoch: 31, loss: 3.855245250672121e-05\n",
      "Epoch: 32, loss: 3.874460911112089e-05\n",
      "Epoch: 33, loss: 3.776654065002781e-05\n",
      "Epoch: 34, loss: 3.851142637964332e-05\n",
      "Epoch: 35, loss: 3.7347755259688056e-05\n",
      "Epoch: 36, loss: 3.878753165818471e-05\n",
      "Epoch: 37, loss: 3.777349335253277e-05\n",
      "Epoch: 38, loss: 3.76650323031929e-05\n",
      "Epoch: 39, loss: 3.905390942246546e-05\n",
      "Epoch: 40, loss: 3.720017110617419e-05\n",
      "Epoch: 41, loss: 3.7169212623280076e-05\n",
      "Epoch: 42, loss: 3.722448061875871e-05\n",
      "Epoch: 43, loss: 3.758777116123661e-05\n",
      "Epoch: 44, loss: 3.8408945479763514e-05\n",
      "Epoch: 45, loss: 3.5815140151093817e-05\n",
      "Epoch: 46, loss: 3.85002246520974e-05\n",
      "Epoch: 47, loss: 3.857169568192231e-05\n",
      "Epoch: 48, loss: 3.807227832689503e-05\n",
      "Epoch: 49, loss: 3.720332143301414e-05\n",
      "Epoch: 50, loss: 3.9030397584663614e-05\n",
      "Epoch: 51, loss: 3.77331631028955e-05\n",
      "Epoch: 52, loss: 3.754220547086163e-05\n",
      "Epoch: 53, loss: 3.730573565308199e-05\n",
      "Epoch: 54, loss: 3.730394619675157e-05\n",
      "Epoch: 57, loss: 3.764112835027219e-05\n",
      "Epoch: 58, loss: 3.878616737884769e-05\n",
      "Epoch: 59, loss: 3.886235289746211e-05\n",
      "Epoch: 60, loss: 3.8824823237948595e-05\n",
      "Epoch: 61, loss: 3.633865855357887e-05\n",
      "Epoch: 62, loss: 3.7264358840468524e-05\n",
      "Epoch: 63, loss: 3.7792239115371654e-05\n",
      "Epoch: 64, loss: 3.859657249331193e-05\n",
      "Epoch: 65, loss: 3.858775747905673e-05\n",
      "Epoch: 66, loss: 3.714131831576295e-05\n",
      "Epoch: 67, loss: 3.82319294515928e-05\n",
      "Epoch: 68, loss: 3.832624792124077e-05\n",
      "Epoch: 69, loss: 3.7404753361739836e-05\n",
      "Epoch: 70, loss: 3.886689293450055e-05\n",
      "Epoch: 71, loss: 3.8740443289368685e-05\n",
      "Epoch: 72, loss: 3.685989890450884e-05\n",
      "Epoch: 73, loss: 3.638912272598392e-05\n",
      "Epoch: 74, loss: 3.92236202907449e-05\n",
      "Epoch: 75, loss: 3.7164387415884616e-05\n",
      "Epoch: 76, loss: 3.738256951267026e-05\n",
      "Epoch: 77, loss: 3.707023993860793e-05\n",
      "Epoch: 78, loss: 3.767299980512361e-05\n",
      "Epoch: 79, loss: 3.833472656684145e-05\n",
      "Epoch: 80, loss: 3.7699979814098976e-05\n",
      "Epoch: 81, loss: 3.792808064898308e-05\n",
      "Epoch: 82, loss: 3.727421438145774e-05\n",
      "Epoch: 83, loss: 3.901943530220691e-05\n",
      "Epoch: 84, loss: 3.808236957261294e-05\n",
      "Epoch: 85, loss: 3.65795505393362e-05\n",
      "Epoch: 86, loss: 3.7139513178912516e-05\n",
      "Epoch: 87, loss: 3.593253569052153e-05\n",
      "Epoch: 88, loss: 3.7593487096177884e-05\n",
      "Epoch: 89, loss: 3.801563764929649e-05\n",
      "Epoch: 90, loss: 3.867896882042742e-05\n",
      "Epoch: 91, loss: 3.727566512894056e-05\n",
      "Epoch: 92, loss: 3.7311287555885925e-05\n",
      "Epoch: 93, loss: 3.740558909611421e-05\n",
      "Epoch: 94, loss: 3.7737161052345154e-05\n",
      "Epoch: 95, loss: 3.8210695165455455e-05\n",
      "Epoch: 96, loss: 3.712487401247772e-05\n",
      "Epoch: 97, loss: 3.74088049032591e-05\n",
      "Epoch: 98, loss: 3.8821225556807904e-05\n",
      "Epoch: 99, loss: 3.6782861846271624e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    reconstruction = tt_tucker[..., 0].torch()\n",
    "    idxs = torch.stack([torch.randint(0, RES, (NUM_SAMPLES, )) for i in range(3)], dim=-1)\n",
    "    loss = (reconstruction[idxs[:, 0], idxs[:, 1], idxs[:, 2]].clamp_max(MAX_TSDF).clamp_min(MIN_TSDF) -\n",
    "            gt_sdf[idxs[:, 0], idxs[:, 1], idxs[:, 2]].clamp_max(MAX_TSDF).clamp_min(MIN_TSDF)).abs().mean()\n",
    "    loss.backward()\n",
    "    print(f'Epoch: {i}, loss: {loss.item()}')\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2087fece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 4.019383251785526e-05\n",
      "Epoch: 1, loss: 3.583481492037336e-05\n",
      "Epoch: 2, loss: 3.9116720256715485e-05\n",
      "Epoch: 3, loss: 3.884746435025234e-05\n",
      "Epoch: 4, loss: 3.750155832617766e-05\n",
      "Epoch: 5, loss: 3.774428726790507e-05\n",
      "Epoch: 6, loss: 3.795775454124457e-05\n",
      "Epoch: 7, loss: 3.6453055640710346e-05\n",
      "Epoch: 8, loss: 3.69181813416022e-05\n",
      "Epoch: 9, loss: 3.790171391379192e-05\n",
      "Epoch: 10, loss: 3.61141585261772e-05\n",
      "Epoch: 11, loss: 3.570005030584897e-05\n",
      "Epoch: 12, loss: 3.877619241930353e-05\n",
      "Epoch: 13, loss: 3.8484673152759384e-05\n",
      "Epoch: 14, loss: 3.608358679638437e-05\n",
      "Epoch: 15, loss: 3.716449964888181e-05\n",
      "Epoch: 16, loss: 3.8267337701679986e-05\n",
      "Epoch: 17, loss: 3.880692067317823e-05\n",
      "Epoch: 18, loss: 3.800318532526119e-05\n",
      "Epoch: 19, loss: 3.668389794644888e-05\n",
      "Epoch: 20, loss: 3.855890155137556e-05\n",
      "Epoch: 21, loss: 3.8275343103724673e-05\n",
      "Epoch: 22, loss: 3.874159783335278e-05\n",
      "Epoch: 23, loss: 3.677468815222015e-05\n",
      "Epoch: 24, loss: 3.69458470457616e-05\n",
      "Epoch: 25, loss: 3.8106573414478156e-05\n",
      "Epoch: 26, loss: 3.7829412321165824e-05\n",
      "Epoch: 27, loss: 3.672429255378236e-05\n",
      "Epoch: 28, loss: 3.665964748410878e-05\n",
      "Epoch: 29, loss: 3.761271508080497e-05\n",
      "Epoch: 30, loss: 3.653516016005375e-05\n",
      "Epoch: 31, loss: 3.665608693376126e-05\n",
      "Epoch: 32, loss: 3.805922121921345e-05\n",
      "Epoch: 33, loss: 3.7092944779995404e-05\n",
      "Epoch: 34, loss: 3.784453366195477e-05\n",
      "Epoch: 35, loss: 3.89936283941219e-05\n",
      "Epoch: 36, loss: 3.743032593559321e-05\n",
      "Epoch: 37, loss: 3.720034485853869e-05\n",
      "Epoch: 38, loss: 3.5935193602714136e-05\n",
      "Epoch: 39, loss: 3.765340479404553e-05\n",
      "Epoch: 40, loss: 3.697666051805315e-05\n",
      "Epoch: 41, loss: 3.648697874303595e-05\n",
      "Epoch: 42, loss: 3.727043806406774e-05\n",
      "Epoch: 43, loss: 3.731417633457069e-05\n",
      "Epoch: 44, loss: 3.763656663782614e-05\n",
      "Epoch: 45, loss: 3.6779310701223757e-05\n",
      "Epoch: 46, loss: 3.695756781983054e-05\n",
      "Epoch: 47, loss: 3.5286665754608296e-05\n",
      "Epoch: 48, loss: 3.783297930401547e-05\n",
      "Epoch: 49, loss: 3.721922644592761e-05\n",
      "Epoch: 50, loss: 3.817181414942631e-05\n",
      "Epoch: 51, loss: 3.798621509894751e-05\n",
      "Epoch: 52, loss: 3.780967886094943e-05\n",
      "Epoch: 53, loss: 3.674559826426941e-05\n",
      "Epoch: 54, loss: 3.672345210438432e-05\n",
      "Epoch: 55, loss: 3.592625496973676e-05\n",
      "Epoch: 56, loss: 3.70030555843479e-05\n",
      "Epoch: 57, loss: 3.699104921057608e-05\n",
      "Epoch: 58, loss: 3.882825378100136e-05\n",
      "Epoch: 61, loss: 3.6312587832207634e-05\n",
      "Epoch: 62, loss: 3.817067484371658e-05\n",
      "Epoch: 63, loss: 3.798117351760769e-05\n",
      "Epoch: 64, loss: 3.7129871405742415e-05\n",
      "Epoch: 65, loss: 3.598428124803887e-05\n",
      "Epoch: 66, loss: 3.741599794177604e-05\n",
      "Epoch: 67, loss: 3.6626110046393484e-05\n",
      "Epoch: 68, loss: 3.557986028768058e-05\n",
      "Epoch: 69, loss: 3.749666704415925e-05\n",
      "Epoch: 70, loss: 3.748201360604335e-05\n",
      "Epoch: 71, loss: 3.675789549716716e-05\n",
      "Epoch: 72, loss: 3.7621416588975614e-05\n",
      "Epoch: 73, loss: 3.785900368318997e-05\n",
      "Epoch: 74, loss: 3.730650358382304e-05\n",
      "Epoch: 75, loss: 3.653531595850852e-05\n",
      "Epoch: 76, loss: 3.662149047268728e-05\n",
      "Epoch: 77, loss: 3.5329276036466606e-05\n",
      "Epoch: 78, loss: 3.695174915846486e-05\n",
      "Epoch: 79, loss: 3.7594649106579094e-05\n",
      "Epoch: 80, loss: 3.695446846770164e-05\n",
      "Epoch: 81, loss: 3.9137982438508165e-05\n",
      "Epoch: 82, loss: 3.78511868093057e-05\n",
      "Epoch: 83, loss: 3.7484098222755025e-05\n",
      "Epoch: 84, loss: 3.6726985582988046e-05\n",
      "Epoch: 85, loss: 3.6518142934451443e-05\n",
      "Epoch: 86, loss: 3.598405791754241e-05\n",
      "Epoch: 87, loss: 3.730695974226424e-05\n",
      "Epoch: 88, loss: 3.6072225869611476e-05\n",
      "Epoch: 89, loss: 3.6986752215843495e-05\n",
      "Epoch: 90, loss: 3.547737599586898e-05\n",
      "Epoch: 91, loss: 3.534497782321926e-05\n",
      "Epoch: 92, loss: 3.482015029086275e-05\n",
      "Epoch: 93, loss: 3.721360367757156e-05\n",
      "Epoch: 94, loss: 3.758879624247386e-05\n",
      "Epoch: 95, loss: 3.759357677050783e-05\n",
      "Epoch: 96, loss: 3.60260927123183e-05\n",
      "Epoch: 97, loss: 3.645453486697947e-05\n",
      "Epoch: 98, loss: 3.526174807805452e-05\n",
      "Epoch: 99, loss: 3.80189511232033e-05\n"
     ]
    }
   ],
   "source": [
    "for i in range(NUM_EPOCHS):\n",
    "    optimizer.zero_grad()\n",
    "    reconstruction = tt_tucker[..., 0].torch()\n",
    "    idxs = torch.stack([torch.randint(0, RES, (NUM_SAMPLES, )) for i in range(3)], dim=-1)\n",
    "    loss = (reconstruction[idxs[:, 0], idxs[:, 1], idxs[:, 2]].clamp_max(MAX_TSDF).clamp_min(MIN_TSDF) -\n",
    "            gt_sdf[idxs[:, 0], idxs[:, 1], idxs[:, 2]].clamp_max(MAX_TSDF).clamp_min(MIN_TSDF)).abs().mean()\n",
    "    loss.backward()\n",
    "    print(f'Epoch: {i}, loss: {loss.item()}')\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dea27bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.6321e-05, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(reconstruction.clamp_max(MAX_TSDF).clamp_min(MIN_TSDF) -\n",
    "        gt_sdf.clamp_max(MAX_TSDF).clamp_min(MIN_TSDF)).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cf44c4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.7646e-05, dtype=torch.float64, grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sqrt((reconstruction.clamp_max(MAX_TSDF).clamp_min(MIN_TSDF) -\n",
    "        gt_sdf.clamp_max(MAX_TSDF).clamp_min(MIN_TSDF))**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9762e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import time\n",
    "\n",
    "coords = torch.tensor(\n",
    "    torch.load(\n",
    "        '/scratch2/data/cape_release/meshes/00032/longshort_flying_eagle/posed/sdf_watertight_longshort_flying_eagle.000001.pt')['coords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "139f1dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction = tt_tucker[..., 0].torch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "510fab0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marching cube finished. Took: 2.0119144916534424 s.\n"
     ]
    }
   ],
   "source": [
    "RES = 512\n",
    "t0 = time.time()\n",
    "verts, faces, _, _ = skimage.measure.marching_cubes(\n",
    "    reconstruction.detach().numpy(),\n",
    "    level=0.,\n",
    "    spacing=(coords[3:] - coords[:3]) / RES)\n",
    "verts = torch.tensor(verts.copy())\n",
    "faces = torch.tensor(faces.copy())\n",
    "print(f'Marching cube finished. Took: {time.time() - t0} s.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fec4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa18bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = trimesh.base.Trimesh(vertices=verts, faces=faces)\n",
    "\n",
    "obj = trimesh.exchange.obj.export_obj(mesh, include_texture=False)\n",
    "with open('./sgd_optimised.obj', 'w') as f:\n",
    "    f.write(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12399f92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<trimesh.Trimesh(vertices.shape=(217280, 3), faces.shape=(434568, 3))>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44bf0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tt_tucker, '../logs/tt_tucker_sgd_optimised_r80_00032_longshort_flying_eagle.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf0c27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
